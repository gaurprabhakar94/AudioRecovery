{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wavfile\n",
    "import os\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of list zero:  [array([-369, -431, -475, ...,  301,  324,  304], dtype=int16), array([-311,  -91, -140, ...,  378,  357,  333], dtype=int16), array([-314, -303, -332, ..., -355, -343, -322], dtype=int16), array([347, 351, 462, ..., 365, 338, 302], dtype=int16), array([-336,  160,   65, ..., -315, -343, -319], dtype=int16), array([ 354,  442,  610, ..., -312, -336, -333], dtype=int16), array([ 397,  531,  638, ..., -357, -386, -353], dtype=int16), array([ 382,  459,  530, ..., -254, -301, -309], dtype=int16), array([-393,   54,  -71, ...,  319,  340,  313], dtype=int16), array([-311, -363, -318, ..., -239, -305, -304], dtype=int16), array([-316, -336, -342, ..., -442, -424, -310], dtype=int16), array([ 335,  392,  481, ..., -302, -314, -304], dtype=int16), array([-361, -226, -238, ..., -286, -311, -343], dtype=int16), array([-309, -323, -333, ..., -301, -300, -304], dtype=int16), array([ 305,  305,  294, ..., -379, -342, -300], dtype=int16), array([ 342,  452,  546, ..., -356, -353, -332], dtype=int16), array([-350, -391, -371, ..., -454, -416, -358], dtype=int16), array([-358, -447, -533, ..., -313, -261, -310], dtype=int16), array([-313, -347, -332, ..., -317, -350, -331], dtype=int16), array([ 332,    0,  -58, ..., -473, -511, -418], dtype=int16), array([-304, -319, -377, ..., -438, -457, -425], dtype=int16), array([-332, -396, -502, ..., -267, -274, -322], dtype=int16), array([-317, -346, -377, ...,  451,  432,  351], dtype=int16), array([ 323,  338,  357, ..., -246, -280, -301], dtype=int16), array([-328, -401, -471, ..., -213, -274, -360], dtype=int16), array([-328, -372, -403, ...,  219,  298,  329], dtype=int16), array([-310, -377, -502, ...,  294,  351,  323], dtype=int16), array([ 310,  339,  351, ..., -327, -351, -311], dtype=int16), array([-309, -385, -459, ...,  363,  364,  306], dtype=int16), array([303, 348, 354, ..., 135, 186, 302], dtype=int16), array([-348, -418, -431, ...,  329,  357,  354], dtype=int16), array([ 306,  399,  455, ..., -228, -345, -344], dtype=int16), array([-326, -362, -376, ..., -315, -321, -316], dtype=int16), array([-317, -199, -303, ...,  393,  409,  384], dtype=int16), array([-302, -312, -103, ..., -338, -333, -348], dtype=int16), array([ 322,  395,  470, ..., -344, -343, -319], dtype=int16), array([355, 425, 481, ..., 398, 372, 332], dtype=int16), array([ 331,  404,  490, ..., -297, -307, -318], dtype=int16), array([-307, -334, -336, ...,  354,  328,  312], dtype=int16), array([-316, -377, -435, ..., -325, -311, -301], dtype=int16), array([ 301,  394,  507, ..., -423, -401, -329], dtype=int16), array([343, 404, 454, ..., 420, 377, 345], dtype=int16), array([ 320,  372,  421, ..., -234, -264, -302], dtype=int16), array([-439, -572, -656, ...,  425,  343,  310], dtype=int16), array([-302, -337, -371, ...,   59, -180, -352], dtype=int16), array([ 305,  365,  419, ..., -313, -342, -346], dtype=int16), array([ 364,  420,  469, ..., -326, -334, -351], dtype=int16), array([-417,  152,  168, ...,  312,  316,  309], dtype=int16), array([ 330,  382,  389, ..., -410, -400, -385], dtype=int16), array([-312, -335, -338, ...,  384,  371,  345], dtype=int16)]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We will keep in 1/4th or 25% of the original audio file. The remaining \n",
    "# percent of the file will be generated via linear extrapolation.\n",
    "#\n",
    "Provided_Portion = 0.25\n",
    "\n",
    "\n",
    "\n",
    "# List to append all the audio files\n",
    "zero = []\n",
    "\n",
    "\n",
    "#\n",
    "# Looping through the dataset and loading up all 50 of the 0_jackson*.wav\n",
    "# files \n",
    "# .read() returns a tuple \n",
    "\n",
    "for filename in os.listdir('free-spoken-digit-dataset-master/recordings'):\n",
    "    if filename.startswith('0_jackson'):\n",
    "        sample = os.path.join('free-spoken-digit-dataset-master/recordings', filename)\n",
    "        sample_rate, audio_data = wavfile.read(sample)\n",
    "        zero.append(audio_data)\n",
    "# Understanding what zero looks like\n",
    "print(\"Contents of list zero: \",zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files in list zero:  50\n",
      "Length of audio clip  0  : 5148\n",
      "Length of audio clip  1  : 4261\n",
      "Length of audio clip  2  : 5451\n",
      "Length of audio clip  3  : 4914\n",
      "Length of audio clip  4  : 4087\n",
      "Length of audio clip  5  : 4716\n",
      "Length of audio clip  6  : 4982\n",
      "Length of audio clip  7  : 5110\n",
      "Length of audio clip  8  : 4423\n",
      "Length of audio clip  9  : 4237\n",
      "Length of audio clip  10  : 5235\n",
      "Length of audio clip  11  : 5103\n",
      "Length of audio clip  12  : 4257\n",
      "Length of audio clip  13  : 4970\n",
      "Length of audio clip  14  : 4797\n",
      "Length of audio clip  15  : 4826\n",
      "Length of audio clip  16  : 4720\n",
      "Length of audio clip  17  : 5136\n",
      "Length of audio clip  18  : 4942\n",
      "Length of audio clip  19  : 4663\n",
      "Length of audio clip  20  : 5165\n",
      "Length of audio clip  21  : 5144\n",
      "Length of audio clip  22  : 4621\n",
      "Length of audio clip  23  : 4788\n",
      "Length of audio clip  24  : 5120\n",
      "Length of audio clip  25  : 4571\n",
      "Length of audio clip  26  : 4939\n",
      "Length of audio clip  27  : 5318\n",
      "Length of audio clip  28  : 5266\n",
      "Length of audio clip  29  : 5015\n",
      "Length of audio clip  30  : 4782\n",
      "Length of audio clip  31  : 4979\n",
      "Length of audio clip  32  : 5277\n",
      "Length of audio clip  33  : 4648\n",
      "Length of audio clip  34  : 4329\n",
      "Length of audio clip  35  : 5711\n",
      "Length of audio clip  36  : 5510\n",
      "Length of audio clip  37  : 5288\n",
      "Length of audio clip  38  : 4999\n",
      "Length of audio clip  39  : 5320\n",
      "Length of audio clip  40  : 5259\n",
      "Length of audio clip  41  : 5394\n",
      "Length of audio clip  42  : 5328\n",
      "Length of audio clip  43  : 5187\n",
      "Length of audio clip  44  : 6273\n",
      "Length of audio clip  45  : 4591\n",
      "Length of audio clip  46  : 5052\n",
      "Length of audio clip  47  : 4431\n",
      "Length of audio clip  48  : 4629\n",
      "Length of audio clip  49  : 5065\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of audio files in list zero: \", len(zero))\n",
    "for i in range(len(zero)):\n",
    "    print(\"Length of audio clip \",i,\" :\" ,len(zero[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lengths are different, we will hard chop all audio clips to be of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4087\n",
      "(50, 4087)\n"
     ]
    }
   ],
   "source": [
    "# Dropping all Nans on the Y axis here and converting the dataset into an\n",
    "# NDArray \n",
    "zero = pd.DataFrame(data = zero, dtype = np.int16)\n",
    "zero.dropna(axis=1, inplace = True)\n",
    "zero = zero.values\n",
    "\n",
    "# 'zero' is currently shaped [n_samples, n_audio_samples],\n",
    "n_audio_samples = zero.shape[1]\n",
    "print(n_audio_samples)\n",
    "print(zero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 4087) (4087,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Creating the linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn.utils.validation import check_random_state\n",
    "rng   = check_random_state(7)  \n",
    "random_idx = rng.randint(zero.shape[0])\n",
    "test  = zero[random_idx]\n",
    "train = np.delete(zero, [random_idx], axis=0)\n",
    "\n",
    "# \n",
    "# Printing out the shape of train, and the shape of test\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Saving the original 'test' clip part \n",
    "wavfile.write('Original Test Clip.wav', sample_rate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the FIRST Provided_Portion * n_audio_samples audio features \n",
    "# from test\n",
    "X_test = test[:int(Provided_Portion*n_audio_samples)]\n",
    "\n",
    "# Grabbing the *remaining* audio features and storing it in y_test.\n",
    "y_test = test[int(Provided_Portion*n_audio_samples):]\n",
    "\n",
    "\n",
    "# \n",
    "# Duplicating the same above process for X_train, y_train.\n",
    "X_train = train[:,:int(Provided_Portion*n_audio_samples)]\n",
    "y_train = train[:,int(Provided_Portion*n_audio_samples):]\n",
    "\n",
    "\n",
    "# .reshape(1, -1) turns [n_features] into [1, n_features].\n",
    "# .reshape(-1, 1) turns [n_samples] into [n_samples, 1].\n",
    "X_test = X_test.reshape(1,-1)\n",
    "y_test = y_test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation R^2 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Fitting model using training data and label\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# \n",
    "# Using the model to predict the 'label' of X_test. \n",
    "y_test_prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_test_prediction = y_test_prediction.astype(dtype=np.int16)\n",
    "\n",
    "\n",
    "# Checking the accuracy score\n",
    "score = model.score(X_test, y_test)\n",
    "print (\"Extrapolation R^2 Score: \", score)\n",
    "\n",
    "\n",
    "#\n",
    "# Taking the first Provided_Portion portion of the test clip and stitching that\n",
    "# together with the abomination the predictor model generated\n",
    "# and then saving the completed audio clip\n",
    "completed_clip = np.hstack((X_test, y_test_prediction))\n",
    "wavfile.write('Extrapolated Clip.wav', sample_rate, completed_clip[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
